{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp38-cp38-win_amd64.whl (162.6 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-0.13.1-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from torchvision) (1.23.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->torchvision) (4.0.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.13.1 torchaudio-0.13.1 torchvision-0.14.1\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from transformers) (1.23.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from transformers) (4.63.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp38-cp38-win_amd64.whl (267 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\r21\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Installing collected packages: pyyaml, filelock, tokenizers, regex, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.9.0 huggingface-hub-0.11.1 pyyaml-6.0 regex-2022.10.31 tokenizers-0.13.2 transformers-4.25.1\n"
     ]
    }
   ],
   "source": [
    "# First, we'll install the transformers library and the small French model we'll be using\n",
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "! pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 420/420 [00:00<00:00, 219kB/s]\n",
      "c:\\Users\\R21\\anaconda3\\envs\\dl\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\R21\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading: 100%|██████████| 545M/545M [00:17<00:00, 31.2MB/s] \n",
      "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-french-europeana-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|██████████| 83.0/83.0 [00:00<00:00, 43.3kB/s]\n",
      "Downloading: 100%|██████████| 227k/227k [00:00<00:00, 696kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'LABEL_0', 'score': 0.5295884, 'index': 1, 'word': 'Bar', 'start': 0, 'end': 3}, {'entity': 'LABEL_1', 'score': 0.6449501, 'index': 2, 'word': '##ack', 'start': 3, 'end': 6}, {'entity': 'LABEL_0', 'score': 0.6252914, 'index': 3, 'word': 'Ob', 'start': 7, 'end': 9}, {'entity': 'LABEL_0', 'score': 0.61272514, 'index': 4, 'word': '##ama', 'start': 9, 'end': 12}, {'entity': 'LABEL_1', 'score': 0.611449, 'index': 5, 'word': 'est', 'start': 13, 'end': 16}, {'entity': 'LABEL_1', 'score': 0.55128473, 'index': 6, 'word': 'né', 'start': 17, 'end': 19}, {'entity': 'LABEL_0', 'score': 0.63517666, 'index': 7, 'word': 'à', 'start': 20, 'end': 21}, {'entity': 'LABEL_1', 'score': 0.5168398, 'index': 8, 'word': 'Hon', 'start': 22, 'end': 25}, {'entity': 'LABEL_0', 'score': 0.5242126, 'index': 9, 'word': '##olu', 'start': 25, 'end': 28}, {'entity': 'LABEL_0', 'score': 0.5194044, 'index': 10, 'word': '##lu', 'start': 28, 'end': 30}, {'entity': 'LABEL_0', 'score': 0.5869533, 'index': 11, 'word': ',', 'start': 30, 'end': 31}, {'entity': 'LABEL_0', 'score': 0.5605997, 'index': 12, 'word': 'dans', 'start': 32, 'end': 36}, {'entity': 'LABEL_0', 'score': 0.5071463, 'index': 13, 'word': 'l', 'start': 37, 'end': 38}, {'entity': 'LABEL_0', 'score': 0.64978707, 'index': 14, 'word': \"'\", 'start': 38, 'end': 39}, {'entity': 'LABEL_0', 'score': 0.58530337, 'index': 15, 'word': 'État', 'start': 39, 'end': 43}, {'entity': 'LABEL_0', 'score': 0.53187054, 'index': 16, 'word': 'd', 'start': 44, 'end': 45}, {'entity': 'LABEL_0', 'score': 0.6497301, 'index': 17, 'word': \"'\", 'start': 45, 'end': 46}, {'entity': 'LABEL_1', 'score': 0.51450825, 'index': 18, 'word': 'Ha', 'start': 46, 'end': 48}, {'entity': 'LABEL_0', 'score': 0.67451173, 'index': 19, 'word': '##wa', 'start': 48, 'end': 50}, {'entity': 'LABEL_0', 'score': 0.67038226, 'index': 20, 'word': '##ï', 'start': 50, 'end': 51}, {'entity': 'LABEL_0', 'score': 0.55773723, 'index': 21, 'word': ',', 'start': 51, 'end': 52}, {'entity': 'LABEL_0', 'score': 0.53196573, 'index': 22, 'word': 'le', 'start': 53, 'end': 55}, {'entity': 'LABEL_0', 'score': 0.7174367, 'index': 23, 'word': '4', 'start': 56, 'end': 57}, {'entity': 'LABEL_0', 'score': 0.63624537, 'index': 24, 'word': 'août', 'start': 58, 'end': 62}, {'entity': 'LABEL_0', 'score': 0.5821007, 'index': 25, 'word': '196', 'start': 63, 'end': 66}, {'entity': 'LABEL_0', 'score': 0.5703797, 'index': 26, 'word': '##1', 'start': 66, 'end': 67}, {'entity': 'LABEL_0', 'score': 0.51475364, 'index': 27, 'word': '.', 'start': 67, 'end': 68}, {'entity': 'LABEL_0', 'score': 0.55870605, 'index': 28, 'word': 'Il', 'start': 69, 'end': 71}, {'entity': 'LABEL_1', 'score': 0.6173474, 'index': 29, 'word': 'est', 'start': 72, 'end': 75}, {'entity': 'LABEL_1', 'score': 0.5385171, 'index': 30, 'word': 'devenu', 'start': 76, 'end': 82}, {'entity': 'LABEL_1', 'score': 0.54948777, 'index': 31, 'word': 'le', 'start': 83, 'end': 85}, {'entity': 'LABEL_0', 'score': 0.58830786, 'index': 32, 'word': '44', 'start': 86, 'end': 88}, {'entity': 'LABEL_0', 'score': 0.5594429, 'index': 33, 'word': '##e', 'start': 88, 'end': 89}, {'entity': 'LABEL_0', 'score': 0.5543715, 'index': 34, 'word': 'président', 'start': 90, 'end': 99}, {'entity': 'LABEL_0', 'score': 0.6693859, 'index': 35, 'word': 'des', 'start': 100, 'end': 103}, {'entity': 'LABEL_0', 'score': 0.56767726, 'index': 36, 'word': 'États', 'start': 104, 'end': 109}, {'entity': 'LABEL_0', 'score': 0.82861143, 'index': 37, 'word': '-', 'start': 109, 'end': 110}, {'entity': 'LABEL_0', 'score': 0.686903, 'index': 38, 'word': 'Unis', 'start': 110, 'end': 114}, {'entity': 'LABEL_0', 'score': 0.5110679, 'index': 39, 'word': '.', 'start': 114, 'end': 115}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Next, we'll import the necessary modules\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "# Now, we'll use the pipeline function to perform NER on some French text\n",
    "# The \"ner\" argument specifies that we want to perform NER, and the \"model\" argument specifies the small French model we'll be using\n",
    "ner_model = pipeline(\"ner\", model=\"dbmdz/bert-base-french-europeana-cased\")\n",
    "\n",
    "# Here is an example of French text to run NER on\n",
    "text = \"Barack Obama est né à Honolulu, dans l'État d'Hawaï, le 4 août 1961. Il est devenu le 44e président des États-Unis.\"\n",
    "\n",
    "# Now we can call the model and pass the text to get the result\n",
    "output = ner_model(text)\n",
    "\n",
    "# The output will be a list of dictionaries, each containing the entity type and the text of the entity\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 440M/440M [00:11<00:00, 36.8MB/s] \n",
      "c:\\Users\\R21\\anaconda3\\envs\\dl\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\R21\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9776379,\n",
       "  'word': 'Apple',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity_group': 'DATE',\n",
       "  'score': 0.97937775,\n",
       "  'word': 'le 1er avril 1976 dans le',\n",
       "  'start': 15,\n",
       "  'end': 41},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9958226,\n",
       "  'word': 'Steve Jobs',\n",
       "  'start': 74,\n",
       "  'end': 85},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99508715,\n",
       "  'word': 'Los Altos',\n",
       "  'start': 87,\n",
       "  'end': 97},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99533045,\n",
       "  'word': 'Californie',\n",
       "  'start': 100,\n",
       "  'end': 111},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9961076,\n",
       "  'word': 'Steve Jobs',\n",
       "  'start': 115,\n",
       "  'end': 126},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.99603254,\n",
       "  'word': 'Steve Wozniak',\n",
       "  'start': 127,\n",
       "  'end': 141},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9957776,\n",
       "  'word': 'Ronald Wayne',\n",
       "  'start': 144,\n",
       "  'end': 157},\n",
       " {'entity_group': 'DATE',\n",
       "  'score': 0.9940308,\n",
       "  'word': 'le 3 janvier 1977 à',\n",
       "  'start': 198,\n",
       "  'end': 218},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.972081,\n",
       "  'word': \"d'Apple Computer\",\n",
       "  'start': 240,\n",
       "  'end': 257},\n",
       " {'entity_group': 'DATE',\n",
       "  'score': 0.9924157,\n",
       "  'word': '30 ans et',\n",
       "  'start': 272,\n",
       "  'end': 282},\n",
       " {'entity_group': 'DATE',\n",
       "  'score': 0.9934852,\n",
       "  'word': 'le 9 janvier 2015.',\n",
       "  'start': 363,\n",
       "  'end': 382}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner-with-dates\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner-with-dates\")\n",
    "\n",
    "\n",
    "##### Process text sample (from wikipedia)\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "nlp(\"Apple est créée le 1er avril 1976 dans le garage de la maison d'enfance de Steve Jobs à Los Altos en Californie par Steve Jobs, Steve Wozniak et Ronald Wayne14, puis constituée sous forme de société le 3 janvier 1977 à l'origine sous le nom d'Apple Computer, mais pour ses 30 ans et pour refléter la diversification de ses produits, le mot « computer » est retiré le 9 janvier 2015.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0e2434964a70057e7f1b699838e8ed135497488d3c5c4287d64ea4c9c64d133"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
